# Transformer Language Modeling on text8 Dataset (PyTorch) 
- Transformer implementation, provided solid base understanding and reference for autoregressive language modeling
  - transformer_lm.py
  - transformer.py
  - lm.py
- Achieved perplexity of 6.47 on the text8 dataset (first 100M Wikipedia characters)
- Implemented a character-level autoregressive model using a TransformerEncoder with sliding-window sequence chunking and learned positional embeddings 
